{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main script which executes the task\n",
    "## roughly they are\n",
    "## 1. initialise the spider\n",
    "## 2. navigate to the live leads page\n",
    "## 3. send requests and get response\n",
    "## 4. repeat\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium import WebElement\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://app.monetizer.com/\"\n",
    "username = \"perry96121@gmail.com\"\n",
    "password = \"Qg8RlLdnl7\"\n",
    "cycle = 5 # limit of number of cycles \n",
    "N = 50 # maximum entries per cycle before conflict resolution\n",
    "save_file = 'save.csv'\n",
    "kim=100 # keeping this number of datapoints in memory for comparison of duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(60)\n",
    "\n",
    "driver.find_element_by_id(\"username\").send_keys(username)\n",
    "driver.find_element_by_id(\"password\").send_keys(password)\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "## need to handle delayed loading of submit button in the landing page \n",
    "try:\n",
    "    element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH,\n",
    "        \"//input[@type='submit']\"\n",
    "        # \"//div[@class='offerList']\"\n",
    "        )))\n",
    "    print('page ready')\n",
    "except TimeoutException:\n",
    "    print('took too long')\n",
    "driver.find_element_by_xpath(\"//input[@type='submit']\").click()\n",
    "\n",
    "driver.implicitly_wait(20)\n",
    "## to the live leads\n",
    "liveleads_button = driver.find_element_by_id(\"menu_liveleadsButton\")\n",
    "liveleads_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "page ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1566.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 1 ====================\n",
      "page ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1566.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### there are  13  new entries #####\n",
      "==================== 2 ====================\n",
      "page ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1392.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### there are  35  new entries #####\n",
      "==================== 3 ====================\n",
      "page ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1392.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### there are  33  new entries #####\n",
      "==================== 4 ====================\n",
      "page ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1474.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### there are  29  new entries #####\n"
     ]
    }
   ],
   "source": [
    "# fun begins here\n",
    "begin_extract(driver, cycle, N, kim, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## we will have to repeat this for 1 to N \n",
    "# time = elements[0].span.contents[0]\n",
    "# infos = elements[0].find_all('span', class_='newsInfo')[0].contents\n",
    "# country = infos[0].replace('\\n','').strip()\n",
    "# tag = infos[1].contents[0]\n",
    "# offerid = infos[5].contents[0]\n",
    "# money = elements[0].find('span',class_=\"theMonie\").contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def begin_extract(driver, limit_cycle, N, kim, save_file):\n",
    "    i = 0\n",
    "    old_data=None\n",
    "    while(i<limit_cycle):\n",
    "        print('====================',i, '====================')\n",
    "        driver.refresh()\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH,\n",
    "                \"//li[@class='offerRow list-group-item']\"\n",
    "                # \"//div[@class='offerList']\"\n",
    "                )))\n",
    "            print('page ready')\n",
    "        except TimeoutException:\n",
    "            print('took too long... will skip this cycle')\n",
    "            break\n",
    "        ## if the page loads the content successfully then proceed \n",
    "        soup_level1=BeautifulSoup(driver.page_source,'lxml')\n",
    "        elements = soup_level1.find_all(\"li\", class_=\"offrRow list-group-item\".split())\n",
    "        ## strip new data\n",
    "        new_data = strip_info(elements, N)\n",
    "        \n",
    "        ## solve conflict between the existing data and the new; to remove duplicated entries \n",
    "        if(i==0):\n",
    "            old_data = new_data\n",
    "            old_data.to_csv(save_file, header=True, index=False, mode='a')\n",
    "        else:\n",
    "            solved = solve_duplicate(old_data,new_data)\n",
    "#             solved.append(old_data)\n",
    "            print(\"##### there are \", solved.shape[0], ' new entries #####')\n",
    "            solved.to_csv(save_file, header=False, index=False, mode='a')\n",
    "            old_data = old_data.append(solved)\n",
    "            old_data = old_data.tail(kim).reset_index(drop=True)\n",
    "            \n",
    "        # lastly, the ugly\n",
    "        i+=1\n",
    "        # sleep for 30 seconds to wait for the next iteration\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def strip_info(elements, N):\n",
    "    times=[]\n",
    "    countries=[]\n",
    "    tags=[]\n",
    "    offerids=[]\n",
    "    monies=[]\n",
    "    for i in tqdm(range(N)):\n",
    "        # extract\n",
    "        time = elements[i].span.contents[0]\n",
    "        infos = elements[i].find_all('span', class_='newsInfo')[0].contents\n",
    "        country = infos[0].replace('\\n','').strip()\n",
    "        tag = infos[1].contents[0]\n",
    "        offerid = infos[5].contents[0]\n",
    "        money = elements[i].find('span',class_=\"theMonie\").contents[0]\n",
    "        # to columns for binding\n",
    "        times.append(time)\n",
    "        countries.append(country)\n",
    "        tags.append(tag)\n",
    "        offerids.append(offerid)\n",
    "        monies.append(money)        \n",
    "    \n",
    "    # append into dataframe and return\n",
    "    df = pd.DataFrame({'Time':times, 'Country':countries, 'Tag':tags, 'Offer ID':offerids, 'Amount':monies})\n",
    "    return(df.iloc[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_duplicate(old, new):\n",
    "    for n in np.flip(np.arange(new.shape[0]), axis=0):\n",
    "        test_new = new.iloc[0:(n+1)]\n",
    "#         print(test_new)\n",
    "        test_old = old.iloc[(old.shape[0]-n-1):old.shape[0]]\n",
    "#         print(test_old)\n",
    "        if (test_new.reset_index(drop=True).equals(test_old.reset_index(drop=True))):\n",
    "            return(new.iloc[(n+1):new.shape[0]].reset_index(drop=True))\n",
    "    print('no new data')\n",
    "    return(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
